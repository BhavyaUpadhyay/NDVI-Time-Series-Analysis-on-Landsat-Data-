# -*- coding: utf-8 -*-
"""NDVI_Time_Series_Analysis_Jaisalmer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kJ9MLe3qKUX19AtJa9gF3Or4G4duBZrU
"""

pip install geehydro

pip install pmdarima

import ee, datetime    # Google Earth Engine
import pandas as pd
import numpy as np
import folium
import geehydro
from datetime import datetime as dt
from IPython.display import Image
from statsmodels.tsa.seasonal import seasonal_decompose
from pmdarima.arima import auto_arima
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

ee.Authenticate()

# Initialize the library.
ee.Initialize(project='ee-bhavyapdhh')

# Visualize the Area Of Interest (AOI) in the map

okanagan_map = folium.Map(location=[26.9157, 70.9083], zoom_start=10)
okanagan_map

# Landsat 8 surface reflectance imagery
# Take images upto 20% cloud coverage
# Take 7 years image data starting at 2013

landsat = ee.ImageCollection("LANDSAT/LC08/C01/T1_SR").\
          filter(ee.Filter.lt('CLOUD_COVER', 20)).\
          filterDate('2013-01-01','2023-01-01')


# setting the Area of Interest (AOI)
okanagan_AOI = ee.Geometry.Rectangle([70.7769, 26.9124, 71.0049, 27.1422])
# filter area
landsat_AOI = landsat.filterBounds(okanagan_AOI)

# Function to get image size
def getImageSize(image):
    # Get the image size in square kilometers
    area = image.geometry().area().divide(1000000)  # in square kilometers
    return image.set('size_sqkm', area)

# Map the function over the image collection
landsat_AOI_with_size = landsat_AOI.map(getImageSize)

# Get the size of each image in square kilometers
image_sizes = landsat_AOI_with_size.aggregate_array('size_sqkm').getInfo()

# Print or use the image sizes as needed
print("Image Sizes (in square kilometers):", image_sizes)

# Function to get image size
def getImageSize(image):
    # Get the image size in square kilometers
    area = image.geometry().area().divide(1000000)  # in square kilometers
    return image.set('size_sqkm', area)

# Map the function over the image collection
landsat_AOI_with_size = landsat_AOI.map(getImageSize)

# Calculate the average size
average_size = landsat_AOI_with_size.reduceColumns(
    reducer=ee.Reducer.mean(),
    selectors=['size_sqkm']
).get('mean').getInfo()

# Print or use the average size as needed
print("Average Image Size (in square kilometers):", average_size)

print('Total number of images :', landsat_AOI.size().getInfo())

# Names of each Landsat 8 band

landsat_AOI.first().bandNames().getInfo()

# Plot the 'first' image in the collection

# List of images
listOfImages = landsat_AOI.toList(landsat_AOI.size())

# Plot in RGB color composite
palette = ['red', 'green', 'blue']
parameters = {'min': 0,
              'max': 1000,
              'dimensions': 512,
              'bands': ['B4', 'B3', 'B2'],
              'region': okanagan_AOI}

okanagan_map.addLayer(ee.Image(listOfImages.get(1)), parameters)
okanagan_map

# Function to calculate 'NDVI' and add a additional band to every images in the collection

def addNDVI(image):
    ndvi = image.normalizedDifference(['B5', 'B4']).rename('NDVI')
    return image.addBands(ndvi)

with_ndvi = landsat_AOI.map(addNDVI)

# Function to calculate 'average NDVI' on every images in the collection

def meanNDVI(image):
    image = ee.Image(image)
    meanDict = image.reduceRegion(reducer = ee.Reducer.mean().setOutputs(['NDVI']),
        geometry = okanagan_AOI,
        scale = image.projection().nominalScale().getInfo(),
                                    maxPixels = 100000,
                                    bestEffort = True);
    return meanDict.get('NDVI').getInfo()

# Calculate 'average NDVI' for every images

listOfImages_ndvi = with_ndvi.select('NDVI').toList(with_ndvi.size())

ndvi_coll = []

for i in range(listOfImages_ndvi.length().getInfo()):
    image = ee.Image(listOfImages_ndvi.get(i-1))
    temp_ndvi = meanNDVI(image)
    ndvi_coll.append(temp_ndvi)

# Extract 'dates' from the image collection

dates = np.array(with_ndvi.aggregate_array("system:time_start").getInfo())
day = [datetime.datetime.fromtimestamp(i/1000).strftime('%Y-%m-%d') for i in (dates)]

# # Make a dataframe with 'day' and 'NDVI' columns

# ndvi_df = pd.DataFrame(ndvi_coll, index = day, columns = ['ndvi'])
# ndvi_df.index = pd.to_datetime(ndvi_df.index, format="%Y/%m/%d")
# ndvi_df.sort_index(ascending = True, inplace = True)

# ndvi_df.head(5)


import pandas as pd

# Assuming 'ndvi_coll' and 'day' are defined earlier
# ndvi_coll = ...
# day = ...

# Create a DataFrame with 'day' and 'NDVI' columns
ndvi_df = pd.DataFrame(ndvi_coll, index=day, columns=['ndvi'])

# Convert the index to datetime
ndvi_df.index = pd.to_datetime(ndvi_df.index, format="%Y-%m-%d")

# Sort the DataFrame by the index
ndvi_df.sort_index(ascending=True, inplace=True)

# Filter the DataFrame to include only dates between 2018-01-01 and 2018-12-31
ndvi_df_2018 = ndvi_df['2017-01-01':'2017-12-31']

# Print the resulting DataFrame
print(ndvi_df_2018.head(50))

# Up-sampple the date column

ndvi_df_daily = ndvi_df.resample('D').median()

# Linear interpolate NDVI data

ndvi_df_daily.interpolate(method='polynomial', order = 1, inplace = True)
ndvi_df_daily.head(5)

plt.figure(figsize=(10,5), dpi=100)
plt.plot(ndvi_df, '*')
plt.plot(ndvi_df_daily)
plt.xlabel('Year', fontsize=15)
plt.ylabel('Average NDVI', fontsize=15)
plt.legend(['Original Data', 'Interpolated Data'])
plt.title("Interpolated NDVI", fontsize=15)
plt.ylim([-1, 1])
plt.show()

# Apply decompomposition on NDVI data

decomposition = seasonal_decompose(ndvi_df_daily, model= 'additive', period = 365)    # additive worked better in terms of seasonality decomposition
                                                            # compared to multiplicative

# assign trend, seasonal components from decomposed data

trend = decomposition.trend
seasonal = decomposition.seasonal


# Plot the original data, the trend, the seasonality, and the residual

plt.figure(figsize=(12,10))
plt.subplot(411)
plt.plot(ndvi_df_daily, label = 'original', linewidth=4)

plt.legend(loc = 'best', fontsize=15)
plt.ylabel('NDVI', fontsize=15)
plt.title('Time-series NDVI decomposition', fontsize=15)
plt.subplot(412)
plt.plot(trend, label = 'Trend', linewidth=4)

plt.legend(loc = 'best', fontsize=15)
plt.ylabel('NDVI', fontsize=15)
plt.subplot(413)
plt.plot(seasonal, label = 'seasonal', linewidth=4)

plt.legend(loc = 'best', fontsize=15)
plt.ylabel('NDVI', fontsize=15)
plt.xlabel('Year', fontsize=15)
plt.tight_layout()

# Plot the original data, the trend, the seasonality data over two years

two_year = (ndvi_df_daily.index>='2017-01-01') & (ndvi_df_daily.index<='2019-01-01')

plt.figure(figsize=(12,10))
plt.subplot(411)
plt.plot(ndvi_df_daily[two_year], label = 'original', linewidth=4)

plt.legend(loc = 'best', fontsize=15)
plt.ylabel('NDVI', fontsize=15)
plt.title('Time-series NDVI decomposition', fontsize=15)
plt.subplot(412)
plt.plot(trend[two_year], label = 'Trend', linewidth=4)

plt.legend(loc = 'best', fontsize=15)
plt.ylabel('NDVI', fontsize=15)
plt.subplot(413)
plt.plot(seasonal[two_year], label = 'seasonal', linewidth=4)

plt.legend(loc = 'best', fontsize=15)
plt.ylabel('NDVI', fontsize=15)
plt.xlabel('Year', fontsize=15)
plt.tight_layout()

# Pick two dates in May and August of 2017

low_index = day.index('2017-01-12')
high_index = day.index('2017-12-30')

# Fetch low/high NDVI images

ndvi_low = ee.Image(listOfImages_ndvi.get(low_index))
ndvi_high = ee.Image(listOfImages_ndvi.get(high_index))

# Plot low NDVI image

palette = ['red', 'yellow', 'green']
ndvi_parameters = {'min': -1,
                   'max': 1,
                   'dimensions': 512,
                   'palette': palette,
                   'region': okanagan_AOI}
okanagan_map.addLayer(ndvi_low, ndvi_parameters)
okanagan_map

# Plot high NDVI image

okanagan_map.addLayer(ndvi_high, ndvi_parameters)
okanagan_map

# split data into train and training set


train_data, test_data = ndvi_df_daily[ndvi_df_daily.index <= '2018-01-01'],\
                        ndvi_df_daily[ndvi_df_daily.index >= '2018-01-01']


# plot the training and testing data

plt.figure(figsize=(14,8))
plt.grid(True)
plt.xlabel('Year', fontsize=15)
plt.ylabel('NDVI', fontsize=15)
plt.plot(train_data, 'green', label='Train data', linewidth=4)
plt.plot(test_data, 'blue', label='Test data', linewidth=4)
plt.title('Time-series NDVI data train-test split', fontsize=15)
plt.ylim([-1,1])
plt.legend(fontsize=15)
plt.show()

# fit auto_arima model

model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0, # minimum p, q values
                      test='adf',                              # uses ADF test to determine differencing order 'd'
                                                               # needed for statioraity
                      max_p=3, max_q=3,                        # maximum p and q values
                      m=7,                                    # frequency of series, m=7 for daily observation
                      d=1,                                     # one step differencing, d=1 can make the data stationary
                                                               # seen from pre-processing step
                      seasonal=True,                           # observed seasonality
                      start_P=0,
                      D=0,                                     # auto_arima will come back with optimal P, Q and D parameters
                                                               # when 'seasonal' parameter is turned on
                      trace=True,
                      error_action='ignore',
                      suppress_warnings=True,
                      stepwise=True)                           # step vs parallel. step is recommended

# Lets review the residual statistics from auto ARIMA model
# residuals should be closer to noise like statistics, which confirms not containing any information from the data

model_autoARIMA.plot_diagnostics(figsize=(14,8))
plt.grid(True)
plt.legend(fontsize=15)
plt.show()

from statsmodels.tsa.arima.model import ARIMA

# Replace the deprecated ARIMA class with the new one
model = ARIMA(train_data, order=(2, 1, 0))
fitted = model.fit()
print(fitted.summary())

# Forecast

# Generate forecast NDVI data
fc, conf_int = fitted.get_forecast(steps=len(test_data), alpha=0.05).predicted_mean, fitted.get_forecast(steps=len(test_data), alpha=0.05).conf_int()
fc_series = pd.Series(fc, index=test_data.index)

# Plot the train, test, and forecast data
plt.figure(figsize=(12, 5), dpi=100)
plt.plot(train_data, label='Training', linewidth=4)
plt.plot(test_data.index, test_data, color='blue', label='Actual NDVI', linewidth=4)
plt.plot(test_data.index, fc, color='orange', label='Predicted NDVI', linewidth=4)

# Extracted confidence intervals directly from the forecast
lower_series = pd.Series(conf_int.iloc[:, 0].values, index=test_data.index)
upper_series = pd.Series(conf_int.iloc[:, 1].values, index=test_data.index)

plt.fill_between(test_data.index, lower_series, upper_series, color='blue', alpha=.2)
plt.title('NDVI Prediction: ARIMA', fontsize=15)
plt.grid(True)
plt.xlabel('Years', fontsize=15)
plt.ylabel('Average NDVI', fontsize=15)
plt.legend(loc='upper left', fontsize=15)
plt.show()

# plot only the train, test and forecast data for 2018-2020


# take forecast data for 2018-2020

plt.figure(figsize=(12,5), dpi=100)
ax=plt.plot(test_data, color = 'blue', label='Actual', linewidth=4)
plt.plot(fc_series.index,fc_series.values, color = 'orange',label='Predicted', linewidth=4)
plt.fill_between(fc_series.index, lower_series, upper_series,
                 color='blue', alpha=.2)
plt.title('NDVI Prediction:ARIMA', fontsize=15)
plt.grid(True)
plt.xlabel('Years', fontsize=15)
plt.ylabel('Average NDVI', fontsize=15)
plt.ylim((-1,1))
plt.legend(loc='upper left', fontsize=15)
plt.fill_between(fc_series.index,.85*test_data.ndvi,1.15*test_data.ndvi,
                 color='white', alpha=.90)

# save the plot
plt.show()

def performance_measure(model, yhat, y):
    # mean squared error
    mse = mean_squared_error(y, yhat)
    #mean absolute error
    mae = mean_absolute_error(y, yhat)
    # root mean squared error
    rmse=np.sqrt(mse)
    #average score
    average=np.mean((mse, mae, rmse))
    # save model performance as dataframe
    metrics=pd.DataFrame({'model': model, 'mse': [mse], 'mae': [mae], 'rmse': [rmse], 'average_score':[average]})
    return metrics

# performance measures for the ARIMA model
fc_ARIMA = fc

ARIMA = performance_measure('ARIMA', fc_ARIMA, test_data)
ARIMA

train_data

test_data

plt.figure(figsize=(12, 5), dpi=100)
plt.plot(train_data.index, train_data['ndvi'], color='blue', label='Train', linewidth=4)
plt.plot(test_data.index, test_data['ndvi'], color='green', label='Test', linewidth=4)
plt.plot(fc_series.index, fc_series.values, color='orange', label='Predicted', linewidth=4)
plt.fill_between(fc_series.index, lower_series, upper_series, color='blue', alpha=.2)
plt.title('NDVI Prediction: ARIMA', fontsize=15)
plt.grid(True)
plt.xlabel('Years', fontsize=15)
plt.ylabel('Average NDVI', fontsize=15)
plt.ylim((-1, 1))
plt.legend(loc='upper left', fontsize=15)

# Fill between train and test data
common_index = fc_series.index.intersection(train_data.index)
plt.fill_between(common_index, 0.85 * train_data.loc[common_index, 'ndvi'], 1.15 * test_data.loc[common_index, 'ndvi'],
                 color='white', alpha=.90)

# Save the plot or display it
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.arima.model import ARIMA
from pmdarima import auto_arima
from sklearn.compose import TransformedTargetRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor

# Assuming you have a DataFrame with 'train_data' and 'test_data'

# Auto SARIMA
model_autoSARIMA = auto_arima(train_data,
                              start_p=0, start_q=0,
                              max_p=3, max_q=3,
                              seasonal=True,
                              m=7,
                              d=1, D=1,
                              trace=True,
                              error_action='ignore',
                              suppress_warnings=True,
                              stepwise=True)

# Fit SARIMA model
order = model_autoSARIMA.get_params()['order']
seasonal_order = model_autoSARIMA.get_params()['seasonal_order']

sarima_model = SARIMAX(train_data,
                      order=order,
                      seasonal_order=seasonal_order,
                      enforce_stationarity=False,
                      enforce_invertibility=False)

fitted_sarima_model = sarima_model.fit()

# Display SARIMA model summary
print(fitted_sarima_model.summary())

# Forecast
fc_sarima = fitted_sarima_model.get_forecast(steps=len(test_data)).predicted_mean
conf_int_sarima = fitted_sarima_model.get_forecast(steps=len(test_data)).conf_int()

# Plot the train, test, and forecast data for SARIMA
plt.figure(figsize=(12, 5), dpi=100)
plt.plot(train_data, label='Training', linewidth=4)
plt.plot(test_data.index, test_data, color='blue', label='Actual NDVI', linewidth=4)
plt.plot(test_data.index, fc_sarima, color='orange', label='Predicted NDVI (SARIMA)', linewidth=4)

# Extracted confidence intervals directly from the forecast
lower_series_sarima = pd.Series(conf_int_sarima.iloc[:, 0].values, index=test_data.index)
upper_series_sarima = pd.Series(conf_int_sarima.iloc[:, 1].values, index=test_data.index)

plt.fill_between(test_data.index, lower_series_sarima, upper_series_sarima, color='blue', alpha=.2)
plt.title('NDVI Prediction: SARIMA', fontsize=15)
plt.grid(True)
plt.xlabel('Years', fontsize=15)
plt.ylabel('Average NDVI', fontsize=15)
plt.legend(loc='upper left', fontsize=15)

# Implementing a Transformer model
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor

# Prepare the data for the transformer model
X_train = np.arange(len(train_data)).reshape(-1, 1)
y_train = train_data.values.reshape(-1, 1)

# Create a transformer model pipeline
transformer_model = make_pipeline(
    StandardScaler(),
    MultiOutputRegressor(RandomForestRegressor(n_estimators=100))
)

# Fit the transformer model
transformer_model.fit(X_train, y_train)

# Forecast with the transformer model
X_test = np.arange(len(train_data), len(train_data) + len(test_data)).reshape(-1, 1)
fc_transformer = transformer_model.predict(X_test)

# Plot the forecast from the transformer model
plt.plot(test_data.index, fc_transformer, color='green', label='Predicted NDVI (Transformer)', linewidth=4)
plt.legend(loc='upper left', fontsize=15)
plt.show()



def performance_measure(model_name, yhat, y):
    # mean squared error
    mse = mean_squared_error(y, yhat)
    # mean absolute error
    mae = mean_absolute_error(y, yhat)
    # root mean squared error
    rmse = np.sqrt(mse)
    # average score
    average = np.mean((mse, mae, rmse))

    # save model performance as a DataFrame
    metrics = pd.DataFrame({
        'model': [model_name],
        'mse': [mse],
        'mae': [mae],
        'rmse': [rmse],
        'average_score': [average]
    })

    return metrics

# Evaluate SARIMA model performance
sarima_metrics = performance_measure('SARIMA', fc_sarima, test_data)

# Display the metrics
print(sarima_metrics)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Train a simple linear regression model
regressor = LinearRegression()
regressor.fit(np.array(train_data.index).reshape(-1, 1), train_data['ndvi'])

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# Assuming 'train_data' and 'test_data' are pandas DataFrame with a column 'ndvi'
# Extract features and target variable
X_train, y_train = np.arange(len(train_data)).reshape(-1, 1), train_data['ndvi'].values
X_test, y_test = np.arange(len(train_data), len(train_data) + len(test_data)).reshape(-1, 1), test_data['ndvi'].values

# Initialize the Linear Regression model
model_linear_regression = LinearRegression()

# Fit the model on the training data
model_linear_regression.fit(X_train, y_train)

# Make predictions on the test data
y_pred = model_linear_regression.predict(X_test)

# Plot the train, test, and linear regression line
plt.figure(figsize=(12, 5), dpi=100)
plt.plot(train_data.index, y_train, label='Training', linewidth=4)
plt.plot(test_data.index, y_test, color='blue', label='Actual NDVI', linewidth=4)
plt.plot(test_data.index, y_pred, color='orange', label='Linear Regression Prediction', linewidth=4)

plt.title('NDVI Prediction: Linear Regression', fontsize=15)
plt.grid(True)
plt.xlabel('Years', fontsize=15)
plt.ylabel('Average NDVI', fontsize=15)
plt.legend(loc='upper left', fontsize=15)
plt.show()

# Performance measures for Linear Regression
linear_regression_metrics = performance_measure('Linear Regression', y_pred, y_test)
linear_regression_metrics

from statsmodels.nonparametric.smoothers_lowess import lowess

# Extract the 'NDVI' column as a one-dimensional array
endog = train_data['ndvi'].values

# Apply LOESS smoothing to the training data
loess_smoothed = lowess(endog, train_data.index, frac=0.15)

# Plot the original training data and the LOESS smoothed data
plt.figure(figsize=(14, 8))
plt.grid(True)
plt.xlabel('Year', fontsize=15)
plt.ylabel('NDVI', fontsize=15)
plt.plot(train_data.index, endog, 'green', label='Train data', linewidth=4)
plt.plot(train_data.index, loess_smoothed[:, 1], 'red', label='LOESS smoothed', linewidth=4)
plt.title('LOESS Smoothing of NDVI data', fontsize=15)
plt.ylim([-1, 1])
plt.legend(fontsize=15)
plt.show()

from statsmodels.tsa.seasonal import seasonal_decompose

# Apply STETS decomposition to the training data
stets_result = seasonal_decompose(train_data, model='stl', period=7)

# Plot the components of the decomposition
plt.figure(figsize=(14, 10))

plt.subplot(4, 1, 1)
plt.plot(stets_result.trend, label='Trend', linewidth=4)
plt.title('Trend Component')

plt.subplot(4, 1, 2)
plt.plot(stets_result.seasonal, label='Seasonal', linewidth=4)
plt.title('Seasonal Component')

plt.subplot(4, 1, 3)
plt.plot(stets_result.resid, label='Residual', linewidth=4)
plt.title('Residual Component')

plt.subplot(4, 1, 4)
plt.plot(train_data, label='Original Data', linewidth=4)
plt.title('Original Data')

plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from keras.models import Sequential
from keras.layers import LSTM, Dense
import matplotlib.pyplot as plt

# Assuming ndvi_df_daily is your original DataFrame with the NDVI data

# Extract the NDVI values and reshape them
ndvi_values = ndvi_df_daily['ndvi'].values.reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler(feature_range=(-1, 1))
ndvi_values_normalized = scaler.fit_transform(ndvi_values)

# Function to prepare data for LSTM
def prepare_data(data, time_steps=1):
    X, y = [], []
    for i in range(len(data) - time_steps):
        a = data[i:(i + time_steps), 0]
        X.append(a)
        y.append(data[i + time_steps, 0])
    return np.array(X), np.array(y)

# Define time steps
time_steps = 10  # You can adjust this based on your data and experimentation

# Prepare the training data
X, y = prepare_data(ndvi_values_normalized, time_steps)

# Reshape input data to be 3D [samples, time steps, features]
X = X.reshape(X.shape[0], X.shape[1], 1)

# Build the LSTM model
model_lstm = Sequential()
model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)))
model_lstm.add(LSTM(units=50))
model_lstm.add(Dense(units=1))
model_lstm.compile(optimizer='adam', loss='mean_squared_error')

# Fit the model
model_lstm.fit(X, y, epochs=50, batch_size=32)

# Prepare test data
test_data_normalized = scaler.transform(test_data['ndvi'].values.reshape(-1, 1))
X_test, y_test = prepare_data(test_data_normalized, time_steps)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Make predictions on test data
y_pred = model_lstm.predict(X_test)
y_pred_actual = scaler.inverse_transform(y_pred.reshape(-1, 1))

# Plot the results
plt.figure(figsize=(12, 5), dpi=100)
plt.plot(test_data.index, test_data['ndvi'].values, label='Actual NDVI', linewidth=4)
plt.plot(test_data.index[time_steps:], y_pred_actual, label='Predicted NDVI', linewidth=4)
plt.title('NDVI Prediction: LSTM', fontsize=15)
plt.xlabel('Years', fontsize=15)
plt.ylabel('Average NDVI', fontsize=15)
plt.legend(loc='upper left', fontsize=15)
plt.show()

# Evaluate the performance of the LSTM model
# Take the last part of the true values to match the length
lstm_metrics = performance_measure('LSTM', y_pred_actual, test_data['ndvi'].values[time_steps:])
print(lstm_metrics)

# Evaluate the performance of the LSTM model
# Take the last part of the true values to match the length
lstm_metrics = performance_measure('LSTM', y_pred_actual, test_data['ndvi'].values[time_steps:])
print(lstm_metrics)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# Feature engineering: create lag features
def create_lag_features(data, lag):
    for i in range(1, lag + 1):
        data[f'lag_{i}'] = data['ndvi'].shift(i)
    return data.dropna()

# Create lag features for training data
lag = 7  # Lag of 7 days, adjust as needed
train_data_lagged = create_lag_features(train_data.copy(), lag)

# Separate features and target variable
X_train = train_data_lagged.drop('ndvi', axis=1)
y_train = train_data_lagged['ndvi']

# Initialize and fit the Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Feature engineering: create lag features for test data
test_data_lagged = create_lag_features(test_data.copy(), lag)

# Separate features and target variable for test data
X_test = test_data_lagged.drop('ndvi', axis=1)

# Ensure the test set has the same number of lagged features as the training set
X_test = X_test.iloc[-len(test_data):]

# Make predictions
y_pred_rf = rf_model.predict(X_test)

# Evaluate performance
rf_metrics = performance_measure('RandomForest', y_pred_rf, test_data['ndvi'].iloc[-len(y_pred_rf):])
print(rf_metrics)

import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense
from tensorflow.keras.optimizers import Adam

# Feature engineering: create lag features
def create_lag_features(data, lag):
    for i in range(1, lag + 1):
        data[f'lag_{i}'] = data['ndvi'].shift(i)
    return data.dropna()

# Create lag features for training data
lag = 7  # Lag of 7 days, adjust as needed
train_data_lagged = create_lag_features(train_data.copy(), lag)

# Separate features and target variable
X_train = train_data_lagged.drop('ndvi', axis=1).values
y_train = train_data_lagged['ndvi'].values

# Normalize the data
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[1])).reshape(X_train.shape)

# Reshape input for CNN
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))

# Build the CNN model
model = Sequential()
model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer=Adam(), loss='mean_squared_error')

# Fit the model
model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)

# Feature engineering: create lag features for test data
test_data_lagged = create_lag_features(test_data.copy(), lag)

# Separate features and target variable for test data
X_test = test_data_lagged.drop('ndvi', axis=1).values

# Normalize the test data
X_test = scaler.transform(X_test.reshape(-1, X_test.shape[1])).reshape(X_test.shape)

# Reshape input for CNN
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Make predictions
y_pred_cnn = model.predict(X_test)

# Evaluate performance
cnn_metrics = performance_measure('CNN', y_pred_cnn.flatten(), test_data['ndvi'].iloc[-len(y_pred_cnn):])
print(cnn_metrics)

# Evaluate performance
cnn_metrics = performance_measure('CNN', y_pred_cnn.flatten(), test_data['ndvi'].iloc[-len(y_pred_cnn):])
print(cnn_metrics)

import matplotlib.pyplot as plt

# Reshape y_pred_cnn to match the original input shape
y_pred_cnn_reshaped = y_pred_cnn.reshape(-1, 1)

# Inverse transform the normalized predictions
y_pred_cnn_original = scaler.inverse_transform(np.concatenate((np.zeros((len(y_pred_cnn_reshaped), lag-1)), y_pred_cnn_reshaped), axis=1))

# Flatten the predictions
y_pred_cnn_original = y_pred_cnn_original[:, -1]

# Plot the actual and predicted NDVI values
plt.figure(figsize=(12, 5), dpi=100)
plt.plot(test_data.index[-len(y_pred_cnn_original):], test_data['ndvi'].iloc[-len(y_pred_cnn_original):], label='Actual NDVI', linewidth=4)
plt.plot(test_data.index[-len(y_pred_cnn_original):], y_pred_cnn_original, label='Predicted NDVI (CNN)', linewidth=4)

plt.title('NDVI Prediction: CNN', fontsize=15)
plt.grid(True)
plt.xlabel('Years', fontsize=15)
plt.ylabel('Average NDVI', fontsize=15)
plt.legend(loc='upper left', fontsize=15)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.arima.model import ARIMA
from pmdarima import auto_arima
from sklearn.compose import TransformedTargetRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.model_selection import GridSearchCV

# Assuming you have a DataFrame with 'train_data' and 'test_data'

# Auto SARIMA
model_autoSARIMA = auto_arima(train_data,
                              start_p=0, start_q=0,
                              max_p=3, max_q=3,
                              seasonal=True,
                              m=7,
                              d=1, D=1,
                              trace=True,
                              error_action='ignore',
                              suppress_warnings=True,
                              stepwise=True)

# Fit SARIMA model
order = model_autoSARIMA.get_params()['order']
seasonal_order = model_autoSARIMA.get_params()['seasonal_order']

sarima_model = SARIMAX(train_data,
                      order=order,
                      seasonal_order=seasonal_order,
                      enforce_stationarity=False,
                      enforce_invertibility=False)

fitted_sarima_model = sarima_model.fit()

# Display SARIMA model summary
print(fitted_sarima_model.summary())

# Forecast
fc_sarima = fitted_sarima_model.get_forecast(steps=len(test_data)).predicted_mean
conf_int_sarima = fitted_sarima_model.get_forecast(steps=len(test_data)).conf_int()

# Plot the train, test, and forecast data for SARIMA
plt.figure(figsize=(12, 5), dpi=100)
plt.plot(train_data, label='Training', linewidth=4)
plt.plot(test_data.index, test_data, color='blue', label='Actual NDVI', linewidth=4)
plt.plot(test_data.index, fc_sarima, color='orange', label='Predicted NDVI (SARIMA)', linewidth=4)

# Extracted confidence intervals directly from the forecast
lower_series_sarima = pd.Series(conf_int_sarima.iloc[:, 0].values, index=test_data.index)
upper_series_sarima = pd.Series(conf_int_sarima.iloc[:, 1].values, index=test_data.index)

plt.fill_between(test_data.index, lower_series_sarima, upper_series_sarima, color='blue', alpha=.2)
plt.title('NDVI Prediction: SARIMA', fontsize=15)
plt.grid(True)
plt.xlabel('Years', fontsize=15)
plt.ylabel('Average NDVI', fontsize=15)
plt.legend(loc='upper left', fontsize=15)

# Implementing a Transformer model with hyperparameter tuning
# Prepare the data for the transformer model
X_train = np.arange(len(train_data)).reshape(-1, 1)
y_train = train_data.values.reshape(-1, 1)

# Create a transformer model pipeline
transformer_model = make_pipeline(
    StandardScaler(),
    MultiOutputRegressor(RandomForestRegressor())
)

# Define the hyperparameter grid for RandomForestRegressor
param_grid = {
    'multioutputregressor__estimator__n_estimators': [50, 100, 150],
    'multioutputregressor__estimator__max_depth': [None, 10, 20, 30],
    # Add more hyperparameters to tune as needed
}

# Perform grid search with cross-validation
grid_search = GridSearchCV(transformer_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Display the best hyperparameters
print("Best Hyperparameters:", grid_search.best_params_)

# Use the best model from the grid search
best_transformer_model = grid_search.best_estimator_

# Forecast with the tuned transformer model
X_test = np.arange(len(train_data), len(train_data) + len(test_data)).reshape(-1, 1)
fc_transformer_tuned = best_transformer_model.predict(X_test)

# Plot the forecast from the tuned transformer model
plt.plot(test_data.index, fc_transformer_tuned, color='red', label='Tuned Predicted NDVI (Transformer)', linewidth=4)
plt.legend(loc='upper left', fontsize=15)
plt.show()

from sklearn.metrics import mean_squared_error
from math import sqrt

# Calculate RMSE for SARIMA model
rmse_sarima = sqrt(mean_squared_error(test_data, fc_sarima))
print(f"RMSE for SARIMA: {rmse_sarima}")

# Calculate RMSE for Tuned Transformer model
rmse_transformer_tuned = sqrt(mean_squared_error(test_data, fc_transformer_tuned))
print(f"RMSE for Tuned Transformer: {rmse_transformer_tuned}")

def performance_measure(model_name, yhat, y):
    # mean squared error
    mse = mean_squared_error(y, yhat)
    # mean absolute error
    mae = mean_absolute_error(y, yhat)
    # root mean squared error
    rmse = np.sqrt(mse)
    # average score
    average = np.mean((mse, mae, rmse))

    # save model performance as a DataFrame
    metrics = pd.DataFrame({
        'model': [model_name],
        'mse': [mse],
        'mae': [mae],
        'rmse': [rmse],
        'average_score': [average],
        'RMSE for Tuned Transformer': [rmse_transformer_tuned]

    })

    return metrics

 # Evaluate SARIMA model performance
sarima_metrics = performance_measure('SARIMA', fc_sarima, test_data)

# Display the metrics
print(sarima_metrics)

from sklearn.metrics import r2_score

# Calculate R-squared for SARIMA model
r2_sarima = r2_score(test_data, fc_sarima)
print(f"R-squared for SARIMA: {r2_sarima}")

from sklearn.metrics import confusion_matrix

# Example: Convert predictions to binary classes (e.g., 1 if above a threshold, 0 otherwise)
threshold = 0.5
binary_predictions = (fc_sarima > threshold).astype(int)
binary_actuals = (test_data > threshold).astype(int)

# Create confusion matrix
conf_matrix = confusion_matrix(binary_actuals, binary_predictions)

print("Confusion Matrix:")
print(conf_matrix)

# Assuming your confusion matrix is stored in conf_matrix
tp = conf_matrix[0, 0]  # True Positives
tn = 0  # True Negatives (assuming there are no negative instances based on the provided confusion matrix)
total_observations = conf_matrix.sum()

accuracy = (tp + tn) / total_observations

print(f"Accuracy: {accuracy * 100:.2f}%")

# Create a dictionary to store performance metrics for each model
all_metrics = {}

# Function to add metrics to the dictionary
def add_metrics(model_name, metrics):
    all_metrics[model_name] = metrics

# ... (rest of your code)

# Performance measures for ARIMA model
fc_ARIMA = fc
ARIMA = performance_measure('ARIMA', fc_ARIMA, test_data)
add_metrics('ARIMA', ARIMA)

# ... (rest of your code)

# Evaluate SARIMA model performance
sarima_metrics = performance_measure('SARIMA', fc_sarima, test_data)
add_metrics('SARIMA', sarima_metrics)

# ... (rest of your code)

# Evaluate Linear Regression model performance
linear_regression_metrics = performance_measure('Linear Regression', y_pred, y_test)
add_metrics('Linear Regression', linear_regression_metrics)

# ... (rest of your code)

# Evaluate LSTM model performance
lstm_metrics = performance_measure('LSTM', y_pred_actual, test_data['ndvi'].values[time_steps:])
add_metrics('LSTM', lstm_metrics)

# ... (rest of your code)

# Evaluate Random Forest model performance
rf_metrics = performance_measure('RandomForest', y_pred_rf, test_data['ndvi'].iloc[-len(y_pred_rf):])
add_metrics('RandomForest', rf_metrics)

# ... (rest of your code)

# Evaluate CNN model performance
cnn_metrics = performance_measure('CNN', y_pred_cnn.flatten(), test_data['ndvi'].iloc[-len(y_pred_cnn):])
add_metrics('CNN', cnn_metrics)

# ... (rest of your code)

# Print RMSE for each model
print("RMSE for Each Model:")
for model_name, metrics in all_metrics.items():
    print(f"{model_name}: {metrics['rmse']}")

# If you included RMSE for Tuned Transformer, you can print it as well
if 'Tuned Transformer' in all_metrics:
    print(f"Tuned Transformer: {all_metrics['Tuned Transformer']['rmse_transformer_tuned']}")

import pandas as pd

# Create a DataFrame to store performance metrics
metrics_df = pd.DataFrame(columns=['Model', 'MSE', 'MAE', 'RMSE', 'Average Score', 'R-squared', 'Accuracy'])

# Function to add metrics to the DataFrame
def add_metrics_to_df(model_name, metrics):
    metrics_df.loc[len(metrics_df)] = [model_name, metrics['mse'][0], metrics['mae'][0], metrics['rmse'][0], metrics['average_score'][0], metrics.get('r2_score', None), metrics.get('accuracy', None)]

# ... (rest of your code)

# Performance measures for ARIMA model
fc_ARIMA = fc
ARIMA = performance_measure('ARIMA', fc_ARIMA, test_data)
add_metrics_to_df('ARIMA', ARIMA)

# ... (rest of your code)

# Evaluate SARIMA model performance
sarima_metrics = performance_measure('SARIMA', fc_sarima, test_data)
add_metrics_to_df('SARIMA', sarima_metrics)

# ... (rest of your code)

# Evaluate Linear Regression model performance
linear_regression_metrics = performance_measure('Linear Regression', y_pred, y_test)
add_metrics_to_df('Linear Regression', linear_regression_metrics)

# ... (rest of your code)

# Evaluate LSTM model performance
lstm_metrics = performance_measure('LSTM', y_pred_actual, test_data['ndvi'].values[time_steps:])
add_metrics_to_df('LSTM', lstm_metrics)

# ... (rest of your code)

# Evaluate Random Forest model performance
rf_metrics = performance_measure('RandomForest', y_pred_rf, test_data['ndvi'].iloc[-len(y_pred_rf):])
add_metrics_to_df('RandomForest', rf_metrics)

# ... (rest of your code)

# Evaluate CNN model performance
cnn_metrics = performance_measure('CNN', y_pred_cnn.flatten(), test_data['ndvi'].iloc[-len(y_pred_cnn):])
add_metrics_to_df('CNN', cnn_metrics)

# ... (rest of your code)

# Print the comparison of metrics
print(metrics_df)

# Visualize the comparison using plots if needed

import matplotlib.pyplot as plt

# Collect performance metrics for all models
sarima_metrics['Model'] = 'SARIMA'
rf_metrics['Model'] = 'RandomForest'
cnn_metrics['Model'] = 'CNN'
transformer_metrics = performance_measure('Tuned Transformer', fc_transformer_tuned, test_data)
transformer_metrics['Model'] = 'Tuned Transformer'
linear_regression_metrics['Model'] = 'Linear Regression'
lstm_metrics['Model'] = 'LSTM'

# Combine all metrics into a single DataFrame
all_metrics = pd.concat([sarima_metrics, rf_metrics, cnn_metrics, transformer_metrics, linear_regression_metrics, lstm_metrics])

# Create a bar chart
plt.figure(figsize=(12, 6))
plt.bar(all_metrics['Model'], all_metrics['average_score'], color=['blue', 'green', 'red', 'purple', 'orange', 'brown'])
plt.title('Model Performance Comparison', fontsize=15)
plt.ylabel('Average Score (MSE, MAE, RMSE)', fontsize=12)
plt.xlabel('Model', fontsize=12)
plt.show()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from math import sqrt

# ... (previous code)

# Create a list to store the metrics dataframes for each model
all_metrics = []

# Add SARIMA metrics
all_metrics.append(sarima_metrics)

# Add RandomForest metrics
rf_metrics = performance_measure('RandomForest', y_pred_rf, test_data['ndvi'].iloc[-len(y_pred_rf):])
all_metrics.append(rf_metrics)

# Add CNN metrics
cnn_metrics = performance_measure('CNN', y_pred_cnn.flatten(), test_data['ndvi'].iloc[-len(y_pred_cnn):])
all_metrics.append(cnn_metrics)

# Add Linear Regression metrics
linear_regression_metrics = performance_measure('Linear Regression', y_pred, y_test)
all_metrics.append(linear_regression_metrics)

# Add ARIMA metrics
arima_metrics = performance_measure('ARIMA', fc_ARIMA, test_data)
all_metrics.append(arima_metrics)

# Create a combined dataframe for all metrics
combined_metrics = pd.concat(all_metrics, ignore_index=True)

# Plotting the bar chart
plt.figure(figsize=(12, 8))
bar_width = 0.2
models = combined_metrics['model']

# Plotting each metric
for i, metric in enumerate(['mse', 'mae', 'rmse', 'average_score']):
    plt.bar(np.arange(len(models)) + i * bar_width, combined_metrics[metric], bar_width, label=metric)

plt.xlabel('Models', fontsize=15)
plt.ylabel('Metric Value', fontsize=15)
plt.title('Model Performance Comparison', fontsize=15)
plt.xticks(np.arange(len(models)) + bar_width, models)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from math import sqrt

# ... (previous code)

# Calculate RMSE for each model
rmse_values = {
    'SARIMA': rmse_sarima,
    'RandomForest': rmse_transformer_tuned,  # Assuming you want to use the tuned transformer model
    'CNN': cnn_metrics['rmse'][0],
    'Linear Regression': linear_regression_metrics['rmse'][0],
    'ARIMA': arima_metrics['rmse'][0]
}

# Find the model with the lowest RMSE
best_model = min(rmse_values, key=rmse_values.get)

# Print and plot the results
print(f"The most accurate model based on RMSE is: {best_model}")

# Plotting the RMSE values for each model
plt.figure(figsize=(10, 6))
plt.bar(rmse_values.keys(), rmse_values.values(), color=['blue', 'orange', 'green', 'red', 'purple'])
plt.xlabel('Models', fontsize=15)
plt.ylabel('Root Mean Squared Error (RMSE)', fontsize=15)
plt.title('Model Accuracy Comparison (Lower RMSE is better)', fontsize=15)
plt.show()

